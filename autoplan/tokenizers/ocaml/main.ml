let rec get_tokens lexbuf =
  match Lexer.token lexbuf with
  | Parser.EOF -> []
  | tok -> tok :: (get_tokens lexbuf)

let rec token_to_json token =
  let open Parser in
  match token with
  | LET -> ("LET", "")
  | WITH -> ("WITH", "")
  | WHILE -> ("WHILE", "")
  | WHEN -> ("WHEN", "")
  | VIRTUAL -> ("VIRTUAL", "")
  | VAL -> ("VAL", "")
  | UNDERSCORE -> ("UNDERSCORE", "")
  | UIDENT str -> ("UIDENT", str)
  | TYPE -> ("TYPE", "")
  | TRY -> ("TRY", "")
  | TRUE -> ("TRUE", "")
  | TO -> ("TO", "")
  | TILDE -> ("TILDE", "")
  | THEN -> ("THEN", "")
  | STRUCT -> ("STRUCT", "")
  | STRING (str, _) -> ("STRING", str)
  | STAR -> ("STAR", "")
  | SIG -> ("SIG", "")
  | SEMISEMI -> ("SEMISEMI", "")
  | SEMI -> ("SEMI", "")
  | RPAREN -> ("RPAREN", "")
  | REC -> ("REC", "")
  | RBRACKET -> ("RBRACKET", "")
  | RBRACE -> ("RBRACE", "")
  | QUOTE -> ("QUOTE", "")
  | QUESTION -> ("QUESTION", "")
  | PRIVATE -> ("PRIVATE", "")
  | PREFIXOP str -> ("PREFIXOP", str)
  | PLUSEQ -> ("PLUSEQ", "")
  | PLUSDOT -> ("PLUSDOT", "")
  | PLUS -> ("PLUS", "")
  | PERCENT -> ("PERCENT", "")
  | OR -> ("OR", "")
  | OPTLABEL str -> ("OPTLABEL", str)
  | OPEN -> ("OPEN", "")
  | OF -> ("OF", "")
  | OBJECT -> ("OBJECT", "")
  | NONREC -> ("NONREC", "")
  | NEW -> ("NEW", "")
  | MUTABLE -> ("MUTABLE", "")
  | MODULE -> ("MODULE", "")
  | MINUSGREATER -> ("MINUSGREATER", "")
  | MINUSDOT -> ("MINUSDOT", "")
  | MINUS -> ("MINUS", "")
  | METHOD -> ("METHOD", "")
  | MATCH -> ("MATCH", "")
  | LPAREN -> ("LPAREN", "")
  | LIDENT str -> ("LIDENT", str)
  | LETOP str -> ("LETOP", str)
  | LET -> ("LET", "")
  | LESSMINUS -> ("LESSMINUS", "")
  | LESS -> ("LESS", "")
  | LBRACKETPERCENTPERCENT -> ("LBRACKETPERCENTPERCENT", "")
  | LBRACKETPERCENT -> ("LBRACKETPERCENT", "")
  | LBRACKETLESS -> ("LBRACKETLESS", "")
  | LBRACKETGREATER -> ("LBRACKETGREATER", "")
  | LBRACKETBAR -> ("LBRACKETBAR", "")
  | LBRACKETATATAT -> ("LBRACKETATATAT", "")
  | LBRACKETATAT -> ("LBRACKETATAT", "")
  | LBRACKETAT -> ("LBRACKETAT", "")
  | LBRACKET -> ("LBRACKET", "")
  | LBRACELESS -> ("LBRACELESS", "")
  | LBRACE -> ("LBRACE", "")
  | LAZY -> ("LAZY", "")
  | LABEL str -> ("LABEL of string", "")
  | INT (str, _) -> ("INT", str)
  | INITIALIZER -> ("INITIALIZER", "")
  | INHERIT -> ("INHERIT", "")
  | INFIXOP4 str -> ("INFIXOP4", str)
  | INFIXOP3 str -> ("INFIXOP3", str)
  | INFIXOP2 str -> ("INFIXOP2", str)
  | INFIXOP1 str -> ("INFIXOP1", str)
  | INFIXOP0 str -> ("INFIXOP0", str)
  | INCLUDE -> ("INCLUDE", "")
  | IN -> ("IN", "")
  | IF -> ("IF", "")
  | HASHOP str -> ("HASHOP", str)
  | HASH -> ("HASH", "")
  | GREATERRBRACKET -> ("GREATERRBRACKET", "")
  | GREATERRBRACE -> ("GREATERRBRACE", "")
  | GREATER -> ("GREATER", "")
  | FUNCTOR -> ("FUNCTOR", "")
  | FUNCTION -> ("FUNCTION", "")
  | FUN -> ("FUN", "")
  | FOR -> ("FOR", "")
  | FLOAT (str, _) -> ("FLOAT", str)
  | FALSE -> ("FALSE", "")
  | EXTERNAL -> ("EXTERNAL", "")
  | EXCEPTION -> ("EXCEPTION", "")
  | EQUAL -> ("EQUAL", "")
  | EOL -> ("EOL", "")
  | EOF -> ("EOF", "")
  | END -> ("END", "")
  | ELSE -> ("ELSE", "")
  | DOWNTO -> ("DOWNTO", "")
  | DOTOP str -> ("DOTOP", "")
  | DOTDOT -> ("DOTDOT", "")
  | DOT -> ("DOT", "")
  | DONE -> ("DONE", "")
  | DOCSTRING _ -> ("DOCSTRING", "")
  | DO -> ("DO", "")
  | CONSTRAINT -> ("CONSTRAINT", "")
  | COMMENT _ -> ("COMMENT", "")
  | COMMA -> ("COMMA", "")
  | COLONGREATER -> ("COLONGREATER", "")
  | COLONEQUAL -> ("COLONEQUAL", "")
  | COLONCOLON -> ("COLONCOLON", "")
  | COLON -> ("COLON", "")
  | CLASS -> ("CLASS", "")
  | CHAR _ -> ("CHAR", "")
  | BEGIN -> ("BEGIN", "")
  | BARRBRACKET -> ("BARRBRACKET", "")
  | BARBAR -> ("BARBAR", "")
  | BAR -> ("BAR", "")
  | BANG -> ("BANG", "")
  | BACKQUOTE -> ("BACKQUOTE", "")
  | ASSERT -> ("ASSERT", "")
  | AS -> ("AS", "")
  | ANDOP str -> ("ANDOP", str)
  | AND -> ("AND", "")
  | AMPERSAND -> ("AMPERSAND", "")
  | AMPERAMPER -> ("AMPERAMPER", "")

let main () =
  let path = "/home/wcrichto/autoplan/data/rainfall/raw/Fall2013-RawData/T1/1.ml" in
  Lexer.init ();
  let lexbuf = Lexing.from_channel stdin in
  let tokens =
    try
      Some (get_tokens lexbuf)
    with Lexer.Error (err, loc) -> None
  in match tokens with
  | Some tokens ->
    (tokens
    |> List.map token_to_json
    |> List.map (fun (key, value) -> Printf.sprintf "[\"%s\", \"%s\"]" key value)
    |> String.concat ","
    |> fun s -> Printf.printf "[%s]" s)
  | None -> Printf.printf "Failed to parse"



let () = main ()
