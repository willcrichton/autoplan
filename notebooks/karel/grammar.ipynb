{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T00:09:53.483530Z",
     "start_time": "2020-06-18T00:09:53.465040Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T00:09:54.809081Z",
     "start_time": "2020-06-18T00:09:53.485879Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import javalang\n",
    "from dataclasses import dataclass\n",
    "from tqdm.auto import tqdm\n",
    "from pickle_cache import PickleCache\n",
    "from javalang import tree\n",
    "from pprint import pprint\n",
    "import textwrap\n",
    "import copy\n",
    "from iterextras import par_for, unzip\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import *\n",
    "\n",
    "sns.set()\n",
    "pcache = PickleCache('.cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions = get_solutions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class BadStatement(Exception):\n",
    "    pass\n",
    "\n",
    "def convert_method(expr):\n",
    "    if not isinstance(expr, tree.MethodInvocation):\n",
    "        raise BadStatement('no')\n",
    "    s = expr.member\n",
    "    return {\n",
    "        'type': s[0].capitalize() + s[1:]\n",
    "    }  \n",
    "\n",
    "def pred_to_json(expr):\n",
    "    if isinstance(expr, tree.BinaryOperation):\n",
    "        raise BadStatement('no')\n",
    "    return convert_method(expr)\n",
    "\n",
    "def selfref(stmt):\n",
    "    if stmt is None:\n",
    "        return None\n",
    "    return {\n",
    "        'type': 'Concrete',\n",
    "        'data': stmt\n",
    "    }\n",
    "\n",
    "\n",
    "def stmt_to_json(stmt):\n",
    "    if isinstance(stmt, list):\n",
    "        if len(stmt) == 0:\n",
    "            raise BadStatement('no')\n",
    "        if len(stmt) == 1:\n",
    "            return stmt_to_json(stmt[0])        \n",
    "        first = stmt_to_json(stmt[0])\n",
    "        second = stmt_to_json(stmt[1:])\n",
    "        return {\n",
    "            'type': 'Seq',\n",
    "            'first': selfref(first),\n",
    "            'second': selfref(second)\n",
    "        }\n",
    "    elif isinstance(stmt, tree.BlockStatement):\n",
    "        return stmt_to_json(stmt.statements)\n",
    "    elif isinstance(stmt, tree.StatementExpression):\n",
    "        expr = stmt.expression\n",
    "        return {\n",
    "            'type': 'Action',\n",
    "            'action': convert_method(expr)\n",
    "        }\n",
    "    elif isinstance(stmt, tree.IfStatement):\n",
    "        return {\n",
    "            'type': 'If',\n",
    "            'pred': pred_to_json(stmt.condition),\n",
    "            'then_': selfref(stmt_to_json(stmt.then_statement)),\n",
    "            'else_': selfref(stmt_to_json(stmt.else_statement))\n",
    "        }\n",
    "    elif isinstance(stmt, tree.WhileStatement):\n",
    "        return {\n",
    "            'type': 'While',\n",
    "            'pred': pred_to_json(stmt.condition),\n",
    "            'body': selfref(stmt_to_json(stmt.body))\n",
    "        }\n",
    "    elif stmt is None:\n",
    "        return None\n",
    "    else:\n",
    "        raise BadStatement(f'Unknown type {type(stmt)}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progs = []\n",
    "for solns in tqdm(solutions.values()):\n",
    "    try:\n",
    "        methods = get_methods(solns[-1])\n",
    "    except IndexError:\n",
    "        continue\n",
    "        \n",
    "    if 'run' not in methods:\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        inlined = Inline(methods).visit(methods['run'])\n",
    "        prog = stmt_to_json(inlined.body)\n",
    "        progs.append(prog)\n",
    "    except (RecursionError, BadStatement):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "progs = pcache.get('progs', lambda: progs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json.dump(progs, open('progs.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "PanicException",
     "evalue": "no entry found for key",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPanicException\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-595db6464baf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgrammar_induction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgrammar_induction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mPanicException\u001b[0m: no entry found for key"
     ]
    }
   ],
   "source": [
    "import grammar_induction\n",
    "grammar_induction.test(progs)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-18T00:11:35.322247Z",
     "start_time": "2020-06-18T00:11:35.298726Z"
    },
    "scrolled": false
   },
   "source": [
    "# import traceback\n",
    "\n",
    "# inlined = {}    \n",
    "# fail = 0\n",
    "# for student, solns in tqdm(list(solutions.items())):\n",
    "#     try:\n",
    "#         methods = get_methods(solns[-1])\n",
    "#         start = copy.deepcopy(methods['run'])\n",
    "#         inlined[student] = Inline(methods).visit(start).body\n",
    "# #     except RecursionError:\n",
    "# #         pass\n",
    "#     except Exception:\n",
    "#         #traceback.print_exc()\n",
    "#         fail += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammars = {}\n",
    "for k, solns in tqdm(list(solutions.items())):   \n",
    "    try:\n",
    "        methods = get_methods(solns[-1])\n",
    "        if 'run' not in methods:\n",
    "            continue\n",
    "\n",
    "        generator = GrammarGenerator(k, methods)\n",
    "        generator.generate(methods['run'])\n",
    "        grammars[k] = Grammar(generator.productions)\n",
    "    except (RecursionError, Unimplemented, IndexError):\n",
    "        pass\n",
    "    except Exception:\n",
    "        print(k)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "productions = {k: p for g in grammars.values() for k, p in g.productions.items()}\n",
    "\n",
    "productions['start'] = Production(rules=[\n",
    "    Rule(\n",
    "        parts=[f'{k}_run'],\n",
    "        prob=1. / len(grammars)\n",
    "    )\n",
    "    for k in grammars.keys()\n",
    "])\n",
    "g = Grammar(productions=productions)\n",
    "g, cs = g.simplify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(g.productions.values())[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = list(solutions.keys())[0]\n",
    "solns = solutions[k]\n",
    "methods = get_methods(solns[-1])\n",
    "prog = GrammarGenerator(k, methods, grammar=False).generate(methods['run'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p = g.sample()\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find all \n",
    "groups = sorted(cs.items(), key=lambda t: len(t[1]))[::-1]\n",
    "for k, group in groups[:50]:\n",
    "    other_names = ['_'.join(k2.split('_')[1:]) for k2 in group if '_rule' not in k2]\n",
    "    print(k, len(group), len(other_names), other_names)\n",
    "    pprint(g.expand(k))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(g, prog):    \n",
    "    ops = {}\n",
    "    for i, part in enumerate(prog.parts):\n",
    "        if isinstance(part, Op):\n",
    "            ops[i] = [parse(g, child) for child in part.children()]\n",
    "            \n",
    "    print(ops)\n",
    "    \n",
    "    n = len(prog.parts)\n",
    "    levels = []\n",
    "    for k in range(1, n+1):   \n",
    "        level = []        \n",
    "\n",
    "        for i in range(0, n-k+1):\n",
    "            matches = []\n",
    "            \n",
    "            for prod_name, prod in g.productions.items():\n",
    "                for rule in prod.rules:                    \n",
    "                    match = True\n",
    "                    \n",
    "                    j = 0                    \n",
    "                    for part in rule.parts:\n",
    "                        if i + j >= len(prog.parts):\n",
    "                            match = False\n",
    "                            break\n",
    "                            \n",
    "                        token = prog.parts[i+j]\n",
    "                        if isinstance(part, str):\n",
    "                            for k2 in range(0, k-1):\n",
    "                                if part in levels[k2][i+j]:\n",
    "                                    j += k2 + 1\n",
    "                                    break\n",
    "                            else:\n",
    "                                match = False\n",
    "                        elif isinstance(part, Op):\n",
    "                            if (part.__class__ == token.__class__ and \n",
    "                              len(part.children()) == len(token.children()) and\n",
    "                              part.cond == token.cond):\n",
    "                                for (child, child_matches) in zip(part.children(), ops[i+j][-1][0]):\n",
    "                                    if child not in child_matches:\n",
    "                                        match = False\n",
    "                                        break\n",
    "                            j += 1\n",
    "                        elif part != token:\n",
    "                            match = False                       \n",
    "                            j += 1\n",
    "                        else:\n",
    "                            j += 1\n",
    "                        \n",
    "                        if not match:\n",
    "                            break\n",
    "                            \n",
    "                    if j == len(prog.parts) - 1 and match:\n",
    "                        matches.append(prod_name)                            \n",
    "                    \n",
    "#                     substr = prog.parts[i:i+k]\n",
    "#                     for j, (l, r) in enumerate(zip(rule.parts, substr)):\n",
    "#                         if isinstance(l, str) and k > 1 and l not in levels[k-2][i+j]:\n",
    "#                             match = False\n",
    "#                         elif (isinstance(l, Op) and \n",
    "#                               l.__class__ == r.__class__ and \n",
    "#                               len(l.children()) == len(r.children()) and\n",
    "#                               l.cond == r.cond):\n",
    "#                             for (child, child_matches) in zip(l.children(), ops[i+j][-1][0]):\n",
    "#                                 if child not in child_matches:\n",
    "#                                     match = False\n",
    "#                         elif l != r:\n",
    "#                             match = False\n",
    "#                         if not match:\n",
    "#                             break\n",
    "#                     if match:\n",
    "#                         matches.append(prod_name)\n",
    "                        \n",
    "            level.append(matches)\n",
    "            \n",
    "        levels.append(level)\n",
    "        \n",
    "    return levels\n",
    "    \n",
    "#parse(g, Block([Action.move]))\n",
    "parse(g, Block([IfNode(Predicate.frontIsClear, Block([Action.move]), None)]))\n",
    "#parse(g, Block([IfNode(Predicate.frontIsBlocked, Block([Action.turnLeft]), None)]))\n",
    "#parse(g, Block([prog.parts[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.productions['student367_rule1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.productions['student416_accountForSingleColumn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute overlap in productions between students\n",
    "# N = len(grammars)\n",
    "# dists = np.zeros((N, N))\n",
    "# index = list(grammars.keys())\n",
    "# rev_index = {s: i for i, s in enumerate(index)}\n",
    "\n",
    "# for k1, grammar1 in tqdm(list(grammars.items())):\n",
    "#     for k2, grammar2 in grammars.items():\n",
    "#         count = 0\n",
    "#         grammar1, grammar2 = normalize_grammars(grammar1, grammar2)\n",
    "#         for p1 in grammar1.productions.values():\n",
    "#             for p2 in grammar2.productions.values():\n",
    "#                 if p1 == p2:\n",
    "#                     count += 1\n",
    "#                     break\n",
    "#         dists[rev_index[k1],rev_index[k2]] = count\n",
    "\n",
    "# dists_sorted = np.dstack(np.unravel_index(np.argsort(dists, axis=None), dists.shape))[0,::-1]\n",
    "# dists_sorted = dists_sorted[dists_sorted[:,0] != dists_sorted[:,1]]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
